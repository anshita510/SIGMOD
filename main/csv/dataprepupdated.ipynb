{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb59555-c9a6-482e-8d4a-eede10200bbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b332c43-79ac-4777-b47f-1bbcf1c2b828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "patients = pd.read_csv('output/csv/patients.csv')\n",
    "observations = pd.read_csv('output/csv/observations.csv')\n",
    "conditions = pd.read_csv('output/csv/conditions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cb4f959-e04e-41c3-80cf-3ea2dcd6a830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421d4f00-7d31-4f73-aeb7-b3074180ecad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0293848-8eb5-4915-9cf8-0ff239351f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "observations = pd.read_csv('output/csv/observations.csv')\n",
    "metrics_of_interest = [\n",
    "    'Diastolic Blood Pressure',\n",
    "    'Systolic Blood Pressure',\n",
    "    'Heart rate',\n",
    "    'Respiratory rate',\n",
    "    'Hemoglobin [Mass/volume] in Blood',\n",
    "    'Hematocrit [Volume Fraction] of Blood by Automated count',\n",
    "    'Leukocytes [\n",
    "    'Erythrocytes [\n",
    "    'Platelets [\n",
    "    'Tobacco smoking status',\n",
    "    'Glucose [Mass/volume] in Blood',\n",
    "    'Cholesterol [Mass/volume] in Serum or Plasma',\n",
    "    'Triglycerides',\n",
    "    'Low Density Lipoprotein Cholesterol',\n",
    "    'Cholesterol in HDL [Mass/volume] in Serum or Plasma',\n",
    "    'Natriuretic peptide.B prohormone N-Terminal [Mass/volume] in Blood by Immunoassay',\n",
    "    'Troponin I.cardiac [Mass/volume] in Serum or Plasma by High sensitivity method',\n",
    "    'Mean blood pressure'\n",
    "]\n",
    "\n",
    "\n",
    "print(\"Columns in observations DataFrame:\", observations.columns.tolist())\n",
    "filtered_observations = observations[observations['DESCRIPTION'].isin(metrics_of_interest)].copy()\n",
    "print(filtered_observations[['PATIENT', 'DESCRIPTION', 'VALUE', 'DATE']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc83fcd-c3cc-462e-91f0-298c6dda5be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoking_status_map = {\n",
    "    'Never smoked tobacco (finding)': 0,\n",
    "    'Ex-smoker (finding)': 1,\n",
    "    'Smokes tobacco daily (finding)': 2\n",
    "}\n",
    "\n",
    "tobacco_data = filtered_observations[filtered_observations['DESCRIPTION'] == 'Tobacco smoking status']\n",
    "tobacco_data['VALUE'] = tobacco_data['VALUE'].map(smoking_status_map)\n",
    "tobacco_data = tobacco_data.dropna(subset=['VALUE'])\n",
    "\n",
    "\n",
    "if tobacco_data.empty:\n",
    "    print(\"No valid entries for 'Tobacco smoking status' after mapping.\")\n",
    "else:\n",
    "    print(f\"Entries found for 'Tobacco smoking status': {len(tobacco_data)}\")\n",
    "    print(tobacco_data[['PATIENT', 'VALUE', 'DATE']].head())\n",
    "\n",
    "\n",
    "filtered_observations = pd.concat([filtered_observations, tobacco_data], ignore_index=True)\n",
    "\n",
    "\n",
    "print(\"Combined filtered observations:\")\n",
    "print(filtered_observations[['PATIENT', 'DESCRIPTION', 'VALUE', 'DATE']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1c84adc-620f-4dfd-a14f-1dfac7a3be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_observations.loc[:, 'VALUE'] = pd.to_numeric(filtered_observations['VALUE'], errors='coerce')\n",
    "filtered_observations = filtered_observations.dropna(subset=['VALUE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0165b195-ccbc-4a01-ba9b-22b4001a1a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probabilities(observation_data, metric_name, threshold):\n",
    "    \"\"\"\n",
    "    Compute initial and transition probabilities for a given metric.\n",
    "    \"\"\"\n",
    "    \n",
    "    metric_data = observation_data[observation_data['DESCRIPTION'] == metric_name]\n",
    "    if len(metric_data) == 0:\n",
    "        print(f\"No data available for metric: {metric_name}\")\n",
    "        return {\n",
    "            'prob_below': 0.0,\n",
    "            'prob_above': 0.0,\n",
    "            'transitions': [0.0, 0.0, 0.0, 0.0]\n",
    "        }\n",
    "    \n",
    "    \n",
    "    prob_below_threshold = len(metric_data[metric_data['VALUE'] <= threshold]) / len(metric_data)\n",
    "    prob_above_threshold = len(metric_data[metric_data['VALUE'] > threshold]) / len(metric_data)\n",
    "    \n",
    "    \n",
    "    total_transitions = len(metric_data) - 1  \n",
    "    if total_transitions == 0:\n",
    "        print(f\"Insufficient data for transitions in metric: {metric_name}\")\n",
    "        return {\n",
    "            'prob_below': prob_below_threshold,\n",
    "            'prob_above': prob_above_threshold,\n",
    "            'transitions': [0.0, 0.0, 0.0, 0.0]\n",
    "        }\n",
    "    \n",
    "    below_to_below = len(metric_data[(metric_data['VALUE'] <= threshold) & \n",
    "                                     (metric_data['VALUE'].shift(-1) <= threshold)]) / total_transitions\n",
    "    below_to_above = len(metric_data[(metric_data['VALUE'] <= threshold) & \n",
    "                                     (metric_data['VALUE'].shift(-1) > threshold)]) / total_transitions\n",
    "    above_to_below = len(metric_data[(metric_data['VALUE'] > threshold) & \n",
    "                                     (metric_data['VALUE'].shift(-1) <= threshold)]) / total_transitions\n",
    "    above_to_above = len(metric_data[(metric_data['VALUE'] > threshold) & \n",
    "                                     (metric_data['VALUE'].shift(-1) > threshold)]) / total_transitions\n",
    "    \n",
    "    return {\n",
    "        'prob_below': prob_below_threshold,\n",
    "        'prob_above': prob_above_threshold,\n",
    "        'transitions': [below_to_below, below_to_above, above_to_below, above_to_above]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0c3e4c-3aef-4258-908f-2ca2743f8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tobacco_data = observations[observations['DESCRIPTION'] == 'Tobacco smoking status']\n",
    "print(tobacco_data['VALUE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5872d8-9e2f-4512-b354-57e0ec4a9c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the observations data (from Synthea output)\n",
    "# Example assumes filtered_observations contains relevant patient metrics.\n",
    "# Columns: ['PATIENT', 'DATE', 'DESCRIPTION', 'VALUE']\n",
    "\n",
    "# Calculate the dynamic threshold for metrics\n",
    "metric_thresholds = {\n",
    "    'Systolic Blood Pressure': filtered_observations[filtered_observations['DESCRIPTION'] == 'Systolic Blood Pressure']['VALUE'].quantile(0.90),\n",
    "    'Diastolic Blood Pressure': filtered_observations[filtered_observations['DESCRIPTION'] == 'Diastolic Blood Pressure']['VALUE'].quantile(0.90),\n",
    "    'Heart rate': filtered_observations[filtered_observations['DESCRIPTION'] == 'Heart rate']['VALUE'].quantile(0.90),\n",
    "    'Respiratory rate': filtered_observations[filtered_observations['DESCRIPTION'] == 'Respiratory rate']['VALUE'].quantile(0.90),\n",
    "    'Hemoglobin [Mass/volume] in Blood': filtered_observations[filtered_observations['DESCRIPTION'] == 'Hemoglobin [Mass/volume] in Blood']['VALUE'].quantile(0.10),\n",
    "    'Hematocrit [Volume Fraction] of Blood by Automated count': filtered_observations[filtered_observations['DESCRIPTION'] == 'Hematocrit [Volume Fraction] of Blood by Automated count']['VALUE'].quantile(0.10),\n",
    "    'Leukocytes [#/volume] in Blood by Automated count': filtered_observations[filtered_observations['DESCRIPTION'] == 'Leukocytes [#/volume] in Blood by Automated count']['VALUE'].quantile(0.90),\n",
    "    'Erythrocytes [#/volume] in Blood by Automated count': filtered_observations[filtered_observations['DESCRIPTION'] == 'Erythrocytes [#/volume] in Blood by Automated count']['VALUE'].quantile(0.10),\n",
    "    'Platelets [#/volume] in Blood by Automated count': filtered_observations[filtered_observations['DESCRIPTION'] == 'Platelets [#/volume] in Blood by Automated count']['VALUE'].quantile(0.90),\n",
    "    'Glucose [Mass/volume] in Blood': filtered_observations[filtered_observations['DESCRIPTION'] == 'Glucose [Mass/volume] in Blood']['VALUE'].quantile(0.90),\n",
    "    'Cholesterol [Mass/volume] in Serum or Plasma': filtered_observations[filtered_observations['DESCRIPTION'] == 'Cholesterol [Mass/volume] in Serum or Plasma']['VALUE'].quantile(0.90),\n",
    "    'Triglycerides': filtered_observations[filtered_observations['DESCRIPTION'] == 'Triglycerides']['VALUE'].quantile(0.90),\n",
    "    'Low Density Lipoprotein Cholesterol': filtered_observations[filtered_observations['DESCRIPTION'] == 'Low Density Lipoprotein Cholesterol']['VALUE'].quantile(0.90),\n",
    "    'Cholesterol in HDL [Mass/volume] in Serum or Plasma': filtered_observations[filtered_observations['DESCRIPTION'] == 'Cholesterol in HDL [Mass/volume] in Serum or Plasma']['VALUE'].quantile(0.10)\n",
    "}\n",
    "\n",
    "# Display the computed thresholds\n",
    "print(\"Dynamic Metric Thresholds:\")\n",
    "for metric, threshold in metric_thresholds.items():\n",
    "    print(f\"{metric}: {threshold}\")\n",
    "\n",
    "\n",
    "# Function to compute probabilities for each metric\n",
    "dbns = {}\n",
    "for metric, threshold in metric_thresholds.items():\n",
    "    probabilities = compute_probabilities(filtered_observations, metric, threshold)\n",
    "    dbns[metric] = probabilities\n",
    "    print(f\"Probabilities for {metric}: {probabilities}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00e473dd-8138-4d63-8ffc-3af88f608a32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install pgmpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ffa758-d94d-41e5-88e8-368dc316a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import HillClimbSearch, BicScore\n",
    "from pgmpy.models import BayesianNetwork\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv('output/csv/observations.csv')\n",
    "\n",
    "\n",
    "\n",
    "print(data.head)\n",
    "\n",
    "hc = HillClimbSearch(data)\n",
    "best_model = hc.estimate(scoring_method=BicScore(data))\n",
    "\n",
    "\n",
    "print(\"Learned Metric Relationships:\")\n",
    "print(best_model.edges())\n",
    "\n",
    "\n",
    "relationships = best_model.edges()\n",
    "with open('metric_relationships.json', 'w') as f:\n",
    "    json.dump([{\"parent\": parent, \"child\": child} for parent, child in relationships], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecae4b8-792f-40ba-abc7-814f77d3fd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed23946-610a-4120-9b0b-a7322ba68ccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e93ec48-85ee-49dd-b468-3a5bf5ef6315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the conditions and observations data from Synthea\n",
    "conditions = pd.read_csv('output/csv/conditions.csv')\n",
    "observations = pd.read_csv('output/csv/observations.csv')\n",
    "\n",
    "# Define the metrics to analyze and their abnormal thresholds\n",
    "metrics = {\n",
    "    'Heart rate': 0.90,  # Top 10% for high heart rate\n",
    "    'Systolic Blood Pressure': 0.90,\n",
    "    'Diastolic Blood Pressure': 0.90,\n",
    "    'Respiratory rate': 0.90,  # Top 10% for abnormal respiratory rate\n",
    "    'Glucose [Mass/volume] in Blood': 0.90,\n",
    "    'Cholesterol [Mass/volume] in Serum or Plasma': 0.90,\n",
    "    'Triglycerides': 0.90,\n",
    "    'Body mass index (BMI) [Ratio]': 0.90\n",
    "}\n",
    "\n",
    "# Convert the VALUE column to numeric, coercing errors to NaN\n",
    "observations['VALUE'] = pd.to_numeric(observations['VALUE'], errors='coerce')\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data_for_csv = []\n",
    "\n",
    "# Iterate over each metric and calculate conditional probabilities\n",
    "for metric, quantile in metrics.items():\n",
    "    # Filter out metric data and calculate the abnormal threshold\n",
    "    metric_data = observations[observations['DESCRIPTION'] == metric]['VALUE'].dropna()\n",
    "    metric_threshold = metric_data.quantile(quantile)\n",
    "\n",
    "    # Filter for abnormal readings based on the metric\n",
    "    if metric == \"Respiratory rate\":\n",
    "        abnormal_readings = observations[\n",
    "            (observations['DESCRIPTION'] == metric) & \n",
    "            (observations['VALUE'] > metric_threshold)  # Higher respiratory rate is abnormal\n",
    "        ]\n",
    "    else:\n",
    "        abnormal_readings = observations[\n",
    "            (observations['DESCRIPTION'] == metric) & \n",
    "            (observations['VALUE'] > metric_threshold)\n",
    "        ]\n",
    "\n",
    "    # Get the patient IDs with abnormal readings\n",
    "    abnormal_patients = abnormal_readings['PATIENT'].unique()\n",
    "\n",
    "    # Filter conditions related to these patients\n",
    "    related_conditions = conditions[conditions['PATIENT'].isin(abnormal_patients)]\n",
    "\n",
    "    # Calculate the total number of patients with the abnormal metric\n",
    "    total_patients_with_abnormal_metric = len(abnormal_patients)\n",
    "\n",
    "    # Calculate the probability of each condition given the abnormal metric\n",
    "    condition_probabilities = related_conditions['DESCRIPTION'].value_counts(normalize=True)\n",
    "\n",
    "    # Append the results to the data list with conditional probabilities\n",
    "    for condition, probability in condition_probabilities.items():\n",
    "        data_for_csv.append([metric, condition, probability])\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df_conditional_probabilities = pd.DataFrame(\n",
    "    data_for_csv, columns=['metric', 'condition', 'conditional_probability']\n",
    ")\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_csv_path = 'output/conditional_probabilities_for_metrics.csv'\n",
    "df_conditional_probabilities.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"CSV file with conditional probabilities for each metric saved at: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c21a4-aa8d-47d6-bd01-9c7859c835ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = pd.read_csv('output/csv/observations.csv')\n",
    "print(observations.head)\n",
    "uniquemetrics = observations['DESCRIPTION'].unique()\n",
    "print(uniquemetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0915911-a024-47d6-9f51-66da4d59a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id='8a2ab9dc-d34e-9f31-9a98-14bcf27330c7'\n",
    "data = observations[(observations['PATIENT'] == patient_id) &\n",
    "                        (observations['DESCRIPTION'].str.contains('Oxygen saturation in Arterial blood', case=False))]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8497d92-8425-4458-8c31-77ced8e7209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load conditions and observations data\n",
    "conditions = pd.read_csv('output/csv/conditions.csv')\n",
    "observations = pd.read_csv('output/csv/observations.csv')\n",
    "\n",
    "# Search for stroke-related terms in the DESCRIPTION column of conditions\n",
    "stroke_related_terms = ['stroke']\n",
    "mask = conditions['DESCRIPTION'].str.contains('|'.join(stroke_related_terms), case=False, na=False)\n",
    "\n",
    "# Filter stroke-related patients\n",
    "stroke_patients = conditions[mask]\n",
    "\n",
    "# Display the first few rows of stroke-related patients\n",
    "# print(\"\\nStroke-Related Patients (Conditions Data):\")\n",
    "# print(stroke_patients[['PATIENT', 'DESCRIPTION', 'CODE']].head())\n",
    "\n",
    "# Get unique patient IDs with stroke-related conditions\n",
    "stroke_patient_ids = stroke_patients['PATIENT'].unique()\n",
    "# print(f\"\\nFound {len(stroke_patient_ids)} patient(s) with stroke-related conditions.\")\n",
    "# print(f\"Stroke Patient IDs: {stroke_patient_ids}\")\n",
    "\n",
    "# Check available metrics for each stroke patient from the observations data\n",
    "for patient_id in stroke_patient_ids:\n",
    "    # print(f\"\\nChecking metrics for Patient ID: {patient_id}\")\n",
    "\n",
    "    # Filter observations for this patient\n",
    "    patient_observations = observations[observations['PATIENT'] == patient_id]\n",
    "    if 'Oxygen saturation in Arterial blood' in patient_observations['DESCRIPTION'].unique():\n",
    "        print(patient_id)\n",
    "\n",
    "    # if not patient_observations.empty:\n",
    "    #     print(f\"Available Metrics for Patient {patient_id}:\")\n",
    "    #     print(patient_observations[['DESCRIPTION', 'VALUE']].dropna())\n",
    "    # else:\n",
    "    #     print(f\"No observations found for Patient {patient_id}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44684642-9304-40af-8b73-63e75585c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "probabilities = pd.read_csv('output/conditional_probabilities_for_metrics.csv')\n",
    "print(probabilities.head())  # Inspect the first few rows\n",
    "uniquemetrics = probabilities['metric'].unique()\n",
    "print(uniquemetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e1b72e6-de26-4bf5-93a9-ad5f141027da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_probabilities(metric):\n",
    "    metric_probs = probabilities[probabilities['metric'] == metric]\n",
    "    if metric_probs.empty:\n",
    "        print(f\"No probabilities found for metric: {metric}\")\n",
    "    return metric_probs.set_index('condition')['conditional_probability'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c95b19-8db6-4f81-b7ee-a3e56f1d8ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate_probs = get_probabilities('Heart rate')\n",
    "if not heart_rate_probs:\n",
    "    print(\"No heart rate probabilities found\")\n",
    "else:\n",
    "    print(f\"Heart rate probabilities: {heart_rate_probs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3c725b-b3e9-4f0a-a569-d69c99791277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pymc as pm\n",
    "import time\n",
    "import signal\n",
    "import sys\n",
    "\n",
    "# Load Synthea data\n",
    "observations = pd.read_csv('output/csv/observations.csv')\n",
    "probabilities = pd.read_csv('output/conditional_probabilities_for_metrics.csv')\n",
    "\n",
    "# Function to get probabilities from the CSV\n",
    "def get_probabilities(metric, threshold=0.05):\n",
    "    metric_probs = probabilities[probabilities['metric'] == metric]\n",
    "    filtered_probs = metric_probs[metric_probs['conditional_probability'] > threshold]\n",
    "    return filtered_probs.set_index('condition')['conditional_probability'].to_dict()\n",
    "\n",
    "# Function to collect blood pressure data\n",
    "def collect_blood_pressure_data(patient_id):\n",
    "    data = observations[(observations['PATIENT'] == patient_id) &\n",
    "                        (observations['DESCRIPTION'].str.contains('Blood Pressure'))]\n",
    "    data['VALUE'] = pd.to_numeric(data['VALUE'], errors='coerce')\n",
    "    return data.dropna(subset=['VALUE'])\n",
    "\n",
    "# Function to build the Bayesian model\n",
    "def build_blood_pressure_causal_model(bp_data, bp_probs):\n",
    "    systolic_data = bp_data[bp_data['DESCRIPTION'] == 'Systolic Blood Pressure']['VALUE']\n",
    "    diastolic_data = bp_data[bp_data['DESCRIPTION'] == 'Diastolic Blood Pressure']['VALUE']\n",
    "\n",
    "    mean_systolic = systolic_data.mean()\n",
    "    std_systolic = systolic_data.std()\n",
    "    mean_diastolic = diastolic_data.mean()\n",
    "    std_diastolic = diastolic_data.std()\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        systolic_prior = pm.Normal('systolic_prior', mu=mean_systolic, sigma=std_systolic)\n",
    "        diastolic_prior = pm.Normal('diastolic_prior', mu=mean_diastolic, sigma=std_diastolic)\n",
    "        trace = pm.sample(1000, chains=2, tune=500, return_inferencedata=False)\n",
    "\n",
    "        bp_risk = np.mean(trace['systolic_prior'] > 140) + np.mean(trace['diastolic_prior'] > 90)\n",
    "\n",
    "    return bp_risk, bp_probs\n",
    "\n",
    "\n",
    "patient_id = '8a2ab9dc-d34e-9f31-9a98-14bcf27330c7'\n",
    "chain = {}\n",
    "\n",
    "bp_data = collect_blood_pressure_data(patient_id)\n",
    "\n",
    "bp_probs = get_probabilities('bSystolic Blood Pressure')\n",
    "bp_risk, cause_probabilities = build_blood_pressure_causal_model(bp_data, bp_probs)\n",
    "bp_status = \"high\" if bp_risk > 0.5 else \"normal\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbfbb2c-dbc6-455c-83e2-dc517e5a1548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2f613c-e3b7-4a6d-8d51-2c52bc034e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cfe782-a52c-46f0-955a-9fe4617d1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load data (same as used in distributed devices)\n",
    "observations = pd.read_csv('output/csv/observations.csv')\n",
    "probabilities = pd.read_csv('output/conditional_probabilities_for_metrics.csv')\n",
    "\n",
    "def compute_central_chain(patient_id):\n",
    "    \"\"\"\n",
    "    Generate a causal chain centrally using all metrics.\n",
    "    \"\"\"\n",
    "    chain = []\n",
    "    visited_metrics = set()\n",
    "    current_metric = \"Heart rate\"  # Start point (can be dynamic)\n",
    "\n",
    "    while current_metric:\n",
    "        print(f\"Processing {current_metric} in central chain...\")\n",
    "        \n",
    "        # Collect data for the metric\n",
    "        metric_data = observations[(observations['PATIENT'] == patient_id) &\n",
    "                                    (observations['DESCRIPTION'] == current_metric)]\n",
    "        if metric_data.empty:\n",
    "            print(f\"No data for {current_metric}. Skipping.\")\n",
    "            break\n",
    "        \n",
    "        # Get probabilities for the current metric\n",
    "        likelihoods = probabilities[probabilities['metric'] == current_metric]\n",
    "        if likelihoods.empty:\n",
    "            print(f\"No probabilities available for {current_metric}.\")\n",
    "            break\n",
    "\n",
    "        # Calculate relevance to other metrics\n",
    "        relevance_scores = {}\n",
    "        for _, row in likelihoods.iterrows():\n",
    "            if row['condition'] not in visited_metrics:\n",
    "                relevance_scores[row['condition']] = row['conditional_probability']\n",
    "\n",
    "        if not relevance_scores:\n",
    "            print(f\"No relevant metrics found for {current_metric}. Ending chain.\")\n",
    "            break\n",
    "\n",
    "        # Determine the next metric based on relevance scores\n",
    "        next_metric = max(relevance_scores, key=relevance_scores.get)\n",
    "        visited_metrics.add(current_metric)\n",
    "\n",
    "        # Add to chain\n",
    "        chain.append({\n",
    "            \"metric\": current_metric,\n",
    "            \"relevance\": relevance_scores,\n",
    "            \"next_metric\": next_metric\n",
    "        })\n",
    "\n",
    "        current_metric = next_metric\n",
    "\n",
    "    print(\"Central chain generation complete.\")\n",
    "    return chain\n",
    "\n",
    "# Test central chain generation\n",
    "patient_id = '86def1b6-28c8-d5e4-39e7-d18bc696eb17'\n",
    "central_chain = compute_central_chain(patient_id)\n",
    "\n",
    "# Save the central chain for comparison\n",
    "with open('central_chain.json', 'w') as f:\n",
    "    json.dump(central_chain, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6affe38c-b84b-4234-b386-0454864a6ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "medication_data = observations[observations['DESCRIPTION'] == 'Medication review due (situation)']\n",
    "print(medication_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2311a0-9db0-44ab-9af7-685c49d6cdbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsenv",
   "language": "python",
   "name": "dsenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
